{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stuck-subject",
   "metadata": {},
   "source": [
    "# Bayesian Regression using PyTorch and Pyro\n",
    "The goal of this notebook is to provide an implementation of a Bayesian Neural Network using PyTorch and Pyro. We first start from the basic by implementing a simple point estimate Regression model using PyTorch. Then, we expand this model by introducing uncertainty estimation. Finally, we generalize it as a Bayesian Neural Network.\n",
    "\n",
    "### Outline\n",
    "- Linear regression using PyTorch\n",
    "- ....\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-eating",
   "metadata": {},
   "source": [
    "The data that we are going to use is the `Rugged dataset` containing information about GDP and the [Terrain Ruggedness Index](https://ourworldindata.org/grapher/terrain-ruggedness-index) of many different countries. In this tutorial, we will try to find how the GDP of a country are related to the heterogenity of its terrain, measured by the Terrain Ruggedness Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "phantom-treasurer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T16:28:41.896775Z",
     "start_time": "2021-06-17T16:28:41.880845Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pyro.nn import PyroModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "vulnerable-petite",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T16:28:43.034747Z",
     "start_time": "2021-06-17T16:28:42.887827Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://d2hg8soec8ck9v.cloudfront.net/datasets/rugged_data.csv', encoding=\"ISO-8859-1\")\n",
    "data = data[np.isfinite(data.rgdppc_2000)]\n",
    "data['rgdppc_2000'] = np.log(data[\"rgdppc_2000\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-ethiopia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T10:26:30.772237Z",
     "start_time": "2021-06-17T10:26:30.757241Z"
    }
   },
   "source": [
    "## Linear regression \n",
    "We are interested in three features:\n",
    "- `rugged`: predictor variable. Represents the Terrain Ruggedness Index for each country. \n",
    "- `cont_africa`: represents if the country is in Africa or not. This is because it was observed a reversed effect between the TRI and the GDP when the country is in Africa.\n",
    "- `rgdppc_2000`: GDP per capita in 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bibliographic-newcastle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T16:29:15.287496Z",
     "start_time": "2021-06-17T16:29:14.520687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 49] loss : 2621.492919921875\n",
      "[iteration 99] loss : 1455.7205810546875\n",
      "[iteration 149] loss : 1008.9662475585938\n",
      "[iteration 199] loss : 735.8435668945312\n",
      "[iteration 249] loss : 539.0015869140625\n",
      "[iteration 299] loss : 396.87579345703125\n",
      "[iteration 349] loss : 299.30426025390625\n",
      "[iteration 399] loss : 235.90505981445312\n",
      "[iteration 449] loss : 196.82069396972656\n",
      "[iteration 499] loss : 173.91293334960938\n",
      "[iteration 549] loss : 161.13006591796875\n",
      "[iteration 599] loss : 154.3326416015625\n",
      "[iteration 649] loss : 150.88641357421875\n",
      "[iteration 699] loss : 149.21994018554688\n",
      "[iteration 749] loss : 148.45138549804688\n",
      "[iteration 799] loss : 148.11331176757812\n",
      "[iteration 849] loss : 147.97154235839844\n",
      "[iteration 899] loss : 147.9148712158203\n",
      "[iteration 949] loss : 147.89329528808594\n",
      "[iteration 999] loss : 147.88546752929688\n",
      "[iteration 1049] loss : 147.88279724121094\n",
      "[iteration 1099] loss : 147.88189697265625\n",
      "[iteration 1149] loss : 147.8816375732422\n",
      "[iteration 1199] loss : 147.88156127929688\n",
      "[iteration 1249] loss : 147.88153076171875\n",
      "[iteration 1299] loss : 147.8815155029297\n",
      "[iteration 1349] loss : 147.8815155029297\n",
      "[iteration 1399] loss : 147.88153076171875\n",
      "[iteration 1449] loss : 147.8815155029297\n",
      "[iteration 1499] loss : 147.88150024414062\n",
      "[iteration 1549] loss : 147.8815155029297\n",
      "[iteration 1599] loss : 147.88153076171875\n",
      "[iteration 1649] loss : 147.88153076171875\n",
      "[iteration 1699] loss : 147.88153076171875\n",
      "[iteration 1749] loss : 147.8815155029297\n",
      "[iteration 1799] loss : 147.88153076171875\n",
      "[iteration 1849] loss : 147.88150024414062\n",
      "[iteration 1899] loss : 147.8815155029297\n",
      "[iteration 1949] loss : 147.88153076171875\n",
      "[iteration 1999] loss : 147.88153076171875\n",
      "The learned parameters are:\n",
      "weights: Parameter containing:\n",
      "tensor([[-1.9480, -0.2028,  0.3934]], requires_grad=True)\n",
      "bias: Parameter containing:\n",
      "tensor([9.2232], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Add an interaction term between `cont_africa` and `rugged` to model separately \n",
    "# the effect for nation within and outside Africa.\n",
    "data['cont_africa_x_rugged'] = data['rugged'] * data['cont_africa']\n",
    "data_tensor = torch.tensor(data[['cont_africa', 'rugged', 'cont_africa_x_rugged', 'rgdppc_2000']].values, dtype=torch.float)\n",
    "x, y = data_tensor[:, :-1], data_tensor[:, -1]\n",
    "\n",
    "# Regression model\n",
    "linear_reg_model = PyroModule[torch.nn.Linear](3, 1)   # similar to torch.nn.Linear\n",
    "\n",
    "# Define loss and optimize\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optim = torch.optim.Adam(linear_reg_model.parameters(), lr=0.05)\n",
    "num_iterations = 2000\n",
    "\n",
    "def train():\n",
    "    y_pred = linear_reg_model(x).squeeze(-1)\n",
    "    loss = loss_fn(y, y_pred)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    return loss\n",
    "\n",
    "for j in range(num_iterations):\n",
    "    loss = train()\n",
    "    if (j+1) % 50 == 0:\n",
    "        print(f'[iteration {j}] loss : {loss.item()}')\n",
    "\n",
    "print(f'The learned parameters are:')\n",
    "print(f'weights: {linear_reg_model.weight}')\n",
    "print(f'bias: {linear_reg_model.bias}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "objective-configuration",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T16:29:54.890757Z",
     "start_time": "2021-06-17T16:29:54.871809Z"
    }
   },
   "outputs": [],
   "source": [
    "a = linear_reg_model(x).squeeze(-1)\n",
    "b = linear_reg_model(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
